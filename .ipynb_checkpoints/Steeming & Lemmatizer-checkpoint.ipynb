{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da6fa67-880b-43ea-b7da-cc659f82dc07",
   "metadata": {},
   "source": [
    "# Steeming\n",
    "### Steeming is a process of reducing a word to its word stem that affixes to suffixes and prefixes or the roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119c2d7e-331b-4dc7-9758-13934e2c575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eating / eaten -> eat \n",
    "# going -> go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d931a1-9bd4-4a46-ae7e-6a87ff3b30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"going\", \"eaten\", \"history\", \"programs\",\"programming\",\"finally\",\"finalize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a6c47-6367-49d8-95f2-3ee2581281db",
   "metadata": {},
   "source": [
    "# Steeming Techniques\n",
    "### - Porter Steemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dae88be-3d6a-4e1c-a21d-222c9cd2512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "steeming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10856f4-6206-4116-a748-1514fe3ab2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "going----->go\n",
      "eaten----->eaten\n",
      "history----->histori\n",
      "programs----->program\n",
      "programming----->program\n",
      "finally----->final\n",
      "finalize----->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+steeming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29041c5a-42c5-46ad-87f6-b31612d23453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steeming.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90ccdba-1b36-4270-bfc1-3400b3503972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steeming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb9472-7900-4579-a384-776dd1f3cbd7",
   "metadata": {},
   "source": [
    "# Regexp Stemmer â€“ RegexpStemmer()\n",
    "### The Regex stemmer uses regular expressions to identify morphological affixes. Substrings that match the regular expressions are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902594ea-2295-4fe3-98f3-68b983fca767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk. stem import RegexpStemmer\n",
    "reg_stemmer = RegexpStemmer(\"ing$|s$|e$|able$\", min = 4)  # Removes \"ing\" from the end of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bb8d67-179c-44ef-957e-068b77730739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602e2445-e340-4a45-9766-58151a29d5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"ingeating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0c066-73f7-4ed3-861a-2c41a8144418",
   "metadata": {},
   "source": [
    "# Snowball Stemmer\n",
    "### better accuracy than potterstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16273a4-3a6a-4e95-b6f3-2f13b9733c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15821314-6d0f-4785-8c13-c12f45d7bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "going--->go\n",
      "eaten--->eaten\n",
      "history--->histori\n",
      "programs--->program\n",
      "programming--->program\n",
      "finally--->final\n",
      "finalize--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59f1fff-0fb8-47f1-8152-5ceed3f0cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steeming. stem(\"fairly\"), steeming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f88a5a4-3ff9-4797-9632-550da49bd17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_stemmer.stem(\"fairly\"), snow_stemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b67fa-7ff0-4093-a6c6-1703a5c55776",
   "metadata": {},
   "source": [
    "# Here we see that Snowballstemmer gives better result in most of the cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c374d1-82a8-4067-88de-d84b588eecb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steeming.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31712730-37e8-4869-b331-1893d9f99b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_stemmer.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5505ec-993c-4435-bad8-4f19bf9b6d1e",
   "metadata": {},
   "source": [
    "# In some of the cases we can not use the steemer so we will look forward with Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc33e9-c973-461e-90bd-a73c05de771e",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "## Lemmatization is a process that reduces words to their base form, or lemma. It's used in natural language processing (NLP), computational linguistics, and chatbots. Lemmatization consists of dictionary of all words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f9d12-8293-4d9e-92d2-ddc4d4b5ca93",
   "metadata": {},
   "source": [
    "# Wordnet Lemmatizer\n",
    "## Which is a thin wrapper arround wordnet corpus. This class uses morphy() function to the wordnet corpus reader class to find a Lemma(root stem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0442db-b638-474e-8420-65123438b2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RUDRANARAYAN\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeab2ca6-1ddc-45de-bb79-52dc953bbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2301874f-2bc1-4eab-9d16-e5071ca06db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS- Noun-n \n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "lemmatizer.lemmatize(\"going\", pos = 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cd2aee5-3116-4a01-94be-9567eed8c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\", pos = 'v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7daaaf3f-8363-4e27-adb0-59c43958e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "going---->go\n",
      "eaten---->eat\n",
      "history---->history\n",
      "programs---->program\n",
      "programming---->program\n",
      "finally---->finally\n",
      "finalize---->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---->\"+lemmatizer.lemmatize(word, pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18a2c8e4-28b0-4e01-b63e-91f95f9b2060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"goes\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef59e710-c361-4d0b-9981-a708f348c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairly'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703ce9e-56c0-4024-8e18-544789a4acd7",
   "metadata": {},
   "source": [
    "## Applications of Lemmatizer:\n",
    "### - Q&A\n",
    "### - Chatbot etc\n",
    "### - Text Summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929f1a3-efec-4c53-baf4-91e44cb8acb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee5475e-8bb8-49b3-b0eb-c3099cb5b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech of Dr APJ Abdul Kalam\n",
    "paragraph = ''' Thanks to the hi-tech media, all of us know what is the creativity. In the process of creativity there are lot of idea or action chains. I am not going to discuss these in detail but, I may add that creativity can definitely lead to discovery, it can lead to invention or it may lead to innovation. Now with this introduction, I must first congratulate the award winners. I am extremely happy to be here for the second annual award function of National Innovation Foundation. It is a matter of great happiness that National Innovation Foundation under the Department of Science and Technology of the Government of India is involved in recognizing, respecting and rewarding unaided innovations and outstanding traditional knowledge experts at the grassroots. The foundations efforts to bring green grassroots innovators into main stream are indeed praise worthy. Here is my suggestion to all my friends here, Dr Mashelkar, Prof Ramamurthy and Prof Anil Gupta. When I visited Nagaland and Arunachal Pradesh, I found the craftwork of the tribal people had tremendous potential. In almost every house, I have seen they create their own products for various applications - ranging from dresses to vessels, protection, safety, security, etc. Every house, more or less has a small hand loom weaving system and they weave beautiful colors and change their dresses every season. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c734f3-a5d2-4bfc-9955-681f2e446def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Thanks to the hi-tech media, all of us know what is the creativity. In the process of creativity there are lot of idea or action chains. I am not going to discuss these in detail but, I may add that creativity can definitely lead to discovery, it can lead to invention or it may lead to innovation. Now with this introduction, I must first congratulate the award winners. I am extremely happy to be here for the second annual award function of National Innovation Foundation. It is a matter of great happiness that National Innovation Foundation under the Department of Science and Technology of the Government of India is involved in recognizing, respecting and rewarding unaided innovations and outstanding traditional knowledge experts at the grassroots. The foundations efforts to bring green grassroots innovators into main stream are indeed praise worthy. Here is my suggestion to all my friends here, Dr Mashelkar, Prof Ramamurthy and Prof Anil Gupta. When I visited Nagaland and Arunachal Pradesh, I found the craftwork of the tribal people had tremendous potential. In almost every house, I have seen they create their own products for various applications - ranging from dresses to vessels, protection, safety, security, etc. Every house, more or less has a small hand loom weaving system and they weave beautiful colors and change their dresses every season. '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08dacfa-7946-4188-9d38-61b0a07d9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c3f6be-f946-4c77-9d52-adf0781fe77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RUDRANARAYAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26474ab9-4b21-4933-9e6b-1d4fa9d7f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3bf900-4132-42c2-b44c-27250e78c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to remove stopwords from the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9dcb9aa-7cbb-402e-9f7b-4258b3d3340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "839835b9-9dfc-4866-bf54-55878f875e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e104cb66-0c37-4a4b-afe8-557015e1037b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6fda095-3e28-4d9e-ac5b-c75cfe949be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords and filter and then apply stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i] = ' '.join(words) # Converting all the words into sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa80075-bfb6-4cf4-9fe0-154a82d1d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank hi-tech media , us know creativ .',\n",
       " 'in process creativ lot idea action chain .',\n",
       " 'i go discuss detail , i may add creativ definit lead discoveri , lead invent may lead innov .',\n",
       " 'now introduct , i must first congratul award winner .',\n",
       " 'i extrem happi second annual award function nation innov foundat .',\n",
       " 'it matter great happi nation innov foundat depart scienc technolog govern india involv recogn , respect reward unaid innov outstand tradit knowledg expert grassroot .',\n",
       " 'the foundat effort bring green grassroot innov main stream inde prais worthi .',\n",
       " 'here suggest friend , dr mashelkar , prof ramamurthi prof anil gupta .',\n",
       " 'when i visit nagaland arunach pradesh , i found craftwork tribal peopl tremend potenti .',\n",
       " 'in almost everi hous , i seen creat product variou applic - rang dress vessel , protect , safeti , secur , etc .',\n",
       " 'everi hous , less small hand loom weav system weav beauti color chang dress everi season .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b0c41-0f37-4c74-843c-61afe969b863",
   "metadata": {},
   "source": [
    "# Apply the same using Snowball Stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa1a26a-6373-4404-8fed-cac5708c19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "604ed8f9-f459-4a23-8e80-993e38aba1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords and filter and then apply Snowball stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [snowballstemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i] = ' '.join(words) # Converting all the words into sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4761bb8-5978-4972-85d3-dbc23af4f76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank hi-tech media , us know creativ .',\n",
       " 'in process creativ lot idea action chain .',\n",
       " 'i go discuss detail , i may add creativ definit lead discoveri , lead invent may lead innov .',\n",
       " 'now introduct , i must first congratul award winner .',\n",
       " 'i extrem happi second annual award function nation innov foundat .',\n",
       " 'it matter great happi nation innov foundat depart scienc technolog govern india involv recogn , respect reward unaid innov outstand tradit knowledg expert grassroot .',\n",
       " 'the foundat effort bring green grassroot innov main stream inde prais worthi .',\n",
       " 'here suggest friend , dr mashelkar , prof ramamurthi prof anil gupta .',\n",
       " 'when i visit nagaland arunach pradesh , i found craftwork tribal peopl tremend potenti .',\n",
       " 'in almost everi hous , i seen creat product various applic - rang dress vessel , protect , safeti , secur , etc .',\n",
       " 'everi hous , less small hand loom weav system weav beauti color chang dress everi season .']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb49eea-bbaa-4747-9db5-041ed4c270b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
